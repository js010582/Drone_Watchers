{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Testing"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "Q08frucOMvrE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Weather_Scrape_DroneWatchers\n",
    "import datetime\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(5000)\n",
    "\n",
    "\n",
    "#User Input:\n",
    "#Weather Station?\n",
    "#Begining Date?\n",
    "#Ending Date?\n",
    "\n",
    "#To Deceive the browser\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "#Test Page\n",
    "#url = 'https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-4/2016-4-4/daily'\n",
    "\n",
    "url = 'https://www.wunderground.com/dashboard/pws/'\n",
    "station = 'IWESTERN315/' #Weather Station is located in South Perth close to Perth where the experiment was taken\n",
    "beginDate = '2016-4-5/'\n",
    "url=url + station + 'table/'+ beginDate + beginDate + 'daily'\n",
    "\n",
    "#--------------------------------------------Download the html data-------------------------------------\n",
    "try:\n",
    "    req = urllib.request.Request(url, headers = headers)\n",
    "    resp = urllib.request.urlopen(req)\n",
    "    \n",
    "    respData = resp.read()\n",
    "\n",
    "    saveFile = open('withHeaders.html','w')\n",
    "    saveFile.write (str(respData))\n",
    "    saveFile.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "\n",
    "#--------------------------------------------Parse the html data-------------------------------------\n",
    "rowData = []\n",
    "\n",
    "with open('withHeaders.html') as html_file:\n",
    "    soup = Soup(html_file, 'lxml')\n",
    "    \n",
    "match = soup.find('lib-history-table', class_= 'ng-star-inserted')\n",
    "date = match.div.h3.text\n",
    "print(date)\n",
    "\n",
    "reducedmatch = match.div.div.div.table.tbody\n",
    "#print(reducedmatch)\n",
    "\n",
    "row_marker = 0\n",
    "for row in reducedmatch.find_all('tr'):\n",
    "    rowData.append(date)\n",
    "    column_marker = 0\n",
    "    columns = row.find_all('td')\n",
    "    for column in columns:\n",
    "        rowData.append(column.text)\n",
    "        #print (column.text)\n",
    "        #print (column_marker)\n",
    "        #print (column.text, end = '')\n",
    "        column_marker+=1    \n",
    "    #print(rowData)\n",
    "    #print(column_marker)\n",
    "    row_marker+=1\n",
    "\n",
    "print(column_marker)\n",
    "print(row_marker)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10875/852162120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1858,
     "status": "ok",
     "timestamp": 1572833796111,
     "user": {
      "displayName": "Jasper Sandhu",
      "photoUrl": "",
      "userId": "14233018147430906323"
     },
     "user_tz": 480
    },
    "id": "1tIJGN2HMvrG",
    "outputId": "a1ba4489-ac9e-49e1-f553-274768003c01"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Lists"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "4HVXBBJrMvrK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Function to split a list into lists within a list\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFSEZxa4MvrK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimenting writing into CSV"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "8VtG-fSHMvrM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import csv\n",
    "\n",
    "sep_rowData = list(chunks(rowData,13)) #Convert into 13 columns\n",
    "\n",
    "with open('filename.csv', 'w', newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    #for row in \n",
    "    thewriter.writerows(sep_rowData)\n",
    "\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPhz-0D0MvrN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a date range that is accepted by the website."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "tACmglrDMvrP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def scrape_station(station, begin_date, end_date):\n",
    "    current_date = datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")+timedelta(days=1)\n",
    "    lookup_URL = 'https://www.wunderground.com/dashboard/pws/{}/table/{}/{}/daily'\n",
    "\n",
    "    while current_date != end_date:\n",
    "        formatted_lookup_URL = lookup_URL.format(station, datetime.strftime(current_date,\"%Y-%-m-%-d\"), datetime.strftime(current_date,\"%Y-%-m-%-d\"))\n",
    "        print (formatted_lookup_URL)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "#Test Command\n",
    "scrape_station('IWESTERN315','2017-9-4','2017-9-7')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2017-9-4/2017-9-4/daily\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2017-9-5/2017-9-5/daily\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2017-9-6/2017-9-6/daily\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2017-9-7/2017-9-7/daily\n"
     ]
    }
   ],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIW-8nRiMvrQ",
    "outputId": "2d9e792b-9dc7-455c-bac2-c7b94ca515ab"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Version"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "6gNHzMvLMvrS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Complete Version\n",
    "#Weather_Scrape_DroneWatchers\n",
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import csv\n",
    "\n",
    "#User Input:\n",
    "#Weather Station?\n",
    "#Begining Date?\n",
    "#Ending Date?\n",
    "\n",
    "#To Deceive the browser\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "#Test Page\n",
    "#url = 'https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-4/2016-4-4/daily'\n",
    "\n",
    "def scrape_station(station, begin_date, end_date):\n",
    "    current_date = datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")+timedelta(days=1)\n",
    "    lookup_URL = 'https://www.wunderground.com/dashboard/pws/{}/table/{}/{}/daily'\n",
    "\n",
    "    while current_date != end_date:\n",
    "        formatted_lookup_URL = lookup_URL.format(station, datetime.strftime(current_date,\"%Y-%-m-%-d\"), datetime.strftime(current_date,\"%Y-%-m-%-d\"))\n",
    "        print (formatted_lookup_URL)\n",
    "\n",
    "        #--------------------------------------------Download the html data-------------------------------------\n",
    "        try:\n",
    "            req = urllib.request.Request(formatted_lookup_URL, headers = headers)\n",
    "            resp = urllib.request.urlopen(req)\n",
    "\n",
    "            respData = resp.read()\n",
    "\n",
    "            saveFile = open('withHeaders.html','w')\n",
    "            saveFile.write (str(respData))\n",
    "            saveFile.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        #--------------------------------------------Parse the html data-------------------------------------\n",
    "        rowData = []\n",
    "        with open('withHeaders.html') as html_file:\n",
    "            soup = Soup(html_file, 'lxml')\n",
    "\n",
    "        match = soup.find('lib-history-table', class_= 'ng-star-inserted')\n",
    "        date = match.div.h3.text\n",
    "        print(date)\n",
    "\n",
    "        reducedmatch = match.div.div.div.table.tbody\n",
    "        #print(reducedmatch)\n",
    "\n",
    "        row_marker = 0\n",
    "        for row in reducedmatch.find_all('tr'):\n",
    "            rowData.append(date)\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                rowData.append(column.text)\n",
    "                #print (column.text)\n",
    "                #print (column_marker)\n",
    "                #print (column.text, end = '')\n",
    "                column_marker+=1    \n",
    "            #print(rowData)\n",
    "            #print(column_marker)\n",
    "            row_marker+=1\n",
    "\n",
    "        #print(column_marker)\n",
    "        print(row_marker,'Total Entries')\n",
    "        print()\n",
    "\n",
    "        #Function to split a list into lists within a list\n",
    "        def chunks(l, n):\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i+n]\n",
    "\n",
    "        sep_rowData = list(chunks(rowData,13)) #Convert into 13 columns\n",
    "\n",
    "        with open('Weather_Scrape.csv', 'a', newline='') as f:\n",
    "            thewriter = csv.writer(f)\n",
    "            #for row in \n",
    "            thewriter.writerows(sep_rowData)\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "    f.close()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m24bSOqiMvrS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "scrape_station('IWESTERN315','2016-4-4','2016-4-13')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-4/2016-4-4/daily\n",
      "April 4, 2016\n",
      "233 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-5/2016-4-5/daily\n",
      "April 5, 2016\n",
      "226 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-6/2016-4-6/daily\n",
      "April 6, 2016\n",
      "222 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-7/2016-4-7/daily\n",
      "April 7, 2016\n",
      "227 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-8/2016-4-8/daily\n",
      "April 8, 2016\n",
      "231 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-9/2016-4-9/daily\n",
      "April 9, 2016\n",
      "224 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-10/2016-4-10/daily\n",
      "April 10, 2016\n",
      "226 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-11/2016-4-11/daily\n",
      "April 11, 2016\n",
      "230 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-12/2016-4-12/daily\n",
      "April 12, 2016\n",
      "222 Total Entries\n",
      "\n",
      "https://www.wunderground.com/dashboard/pws/IWESTERN315/table/2016-4-13/2016-4-13/daily\n",
      "April 13, 2016\n",
      "225 Total Entries\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12056,
     "status": "ok",
     "timestamp": 1572833890640,
     "user": {
      "displayName": "Jasper Sandhu",
      "photoUrl": "",
      "userId": "14233018147430906323"
     },
     "user_tz": 480
    },
    "id": "I-4Zp_r1MvrU",
    "outputId": "822cbd31-7406-4d9d-c463-8c0e6d549e6b"
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Scrape_DroneWatchers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('ML': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "b2e8b71bb4bee9c3c548cf1f5714f357b502b0208400e480c8a839ad088951a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}